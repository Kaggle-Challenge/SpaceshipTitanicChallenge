
# Import necessary libaries
!pip install shap
!pip install catboost
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.ensemble import RandomForestClassifier
from catboost import CatBoostClassifier
from sklearn.decomposition import PCA
from sklearn.pipeline import Pipeline

import shap
import warnings
warnings.filterwarnings("ignore")

# Load Data
train = pd.read_csv('https://raw.githubusercontent.com/Revathi343664/SpaceshipTitanicChallenge/refs/heads/main/train.csv')
test = pd.read_csv('https://raw.githubusercontent.com/Revathi343664/SpaceshipTitanicChallenge/refs/heads/main/test.csv')
submission = pd.read_csv('https://raw.githubusercontent.com/Revathi343664/SpaceshipTitanicChallenge/refs/heads/main/sample_submission.csv')
test_ids = test['PassengerId']

train.info()
train.head()
train.describe(include='all')

# Missing Values Overview
print("Missing values in train:\n", train.isnull().sum())

# Cabin and Name Colums Imputation
for df in [train, test]:
    df['Cabin'].fillna('Unknown/Unknown/0', inplace=True)
    df['Name'].fillna('Unknown', inplace=True)

# Missing Values Overview
print("Missing values in train:\n", train.isnull().sum())

# Initial EDA
import matplotlib.patches as mpatches
fig, axes = plt.subplots(1, 3, figsize=(15, 4))
sns.histplot(train['Age'].dropna(), kde=True, ax=axes[0]).set(title='Age Distribution')
sns.countplot(x='VIP', data=train, ax=axes[1]).set(title='VIP Count'); axes[1].set_xticklabels(['Non-VIP (False)', 'VIP (True)'])
sns.countplot(x='CryoSleep', data=train, ax=axes[2]).set(title='CryoSleep Count'); axes[2].set_xticklabels(['Awake  (False)', 'In CryoSleep (True)'])
plt.tight_layout()
plt.show()

# Distribution of passengers across different Decks, segmented by Transported status
# Distribution of passengers by Cabin Side, segmented by Transported status
# Boxplot of Cabin numbers showing how they vary with Transported status

fig, axes = plt.subplots(1, 3, figsize=(18, 5))

sns.countplot(x='Deck', hue='Transported', data=train, ax=axes[0]).set_title('Transported by Deck')
sns.countplot(x='Side', hue='Transported', data=train, ax=axes[1]).set_title('Transported by Side'); axes[1].set_xticklabels(['P (Port)', 'S (Starboard)'])
sns.boxplot(x='Transported', y='CabinNum', data=train, ax=axes[2]).set_title('CabinNum vs Transported')



plt.tight_layout()
plt.show()

# Feature Engineering
for df in [train, test]:
    df['TotalExpenses'] = df[['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']].sum(axis=1)

# Encoding + Scaling
le = LabelEncoder()
for c in cols_cat:
    train[c] = le.fit_transform(train[c].astype(str))
    test[c] = le.transform(test[c].astype(str))

scaler = StandardScaler()
train[cols_num + ['TotalExpenses']] = scaler.fit_transform(train[cols_num + ['TotalExpenses']])
test[cols_num + ['TotalExpenses']] = scaler.transform(test[cols_num + ['TotalExpenses']])

# Enhanced EDA

# Correlation matrix
plt.figure(figsize=(12, 8))
sns.heatmap(train[cols_num + ['TotalExpenses'] + ['Transported']].corr(), annot=True, cmap='coolwarm')
plt.title("Correlation Matrix")
plt.show()

# Scatter Plots
plt.figure(figsize=(8,6))
sns.scatterplot(x='Age', y='TotalExpenses', hue='Transported', data=train)
plt.title('Age vs TotalExpenses')
plt.show()

plt.figure(figsize=(8,6))
sns.scatterplot(x='Spa', y='VRDeck', hue='Transported', data=train)
plt.title('Spa vs VRDeck')
plt.show()

# Data Preparation for Modeling
X = train.drop(['PassengerId','Name','Cabin','Transported'], axis=1)
y = train['Transported'].astype(int)
X_test = test.drop(['PassengerId','Name','Cabin'], axis=1)

# Check for missing values in X and X_test
print(X.isnull().sum())
print(X_test.isnull().sum())

# Verify that columns in X_test match those in X both in name and order
print("Columns match:" , list(X.columns) == list(X_test.columns))

# Let's decide how many components to keep. We can visualize explained variance.
pca = PCA().fit(X)
plt.figure(figsize=(10, 6))
plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('Number of Components')
plt.ylabel('Cumulative Explained Variance')
plt.title('PCA - Cumulative Explained Variance')
plt.grid(True)
plt.show()

# Based on the plot, we have choosen 10 number of components that explain a good portion of variance nearly 95% because of typical dataset.
# We have adjusted `n_components` based on the Elbow point or desired explained variance from the plot above.
pca_n_components = min(10, X.shape[1])

pca_transformer = PCA(n_components=pca_n_components)
X_pca = pca_transformer.fit_transform(X)
X_test_pca = pca_transformer.transform(X_test)

print(f"\nOriginal number of features: {X.shape[1]}")
print(f"Number of features after PCA: {X_pca.shape[1]}")

# Model Training with Hyperparameter Tuning and Cross-Validation

# Creating StratifiedKFold for robust evaluation
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# XGBoost Classifier
print("\n--- Training XGBoost Classifier with Hyperparameter Tuning ---")

# Define parameter grid for RandomizedSearchCV (more efficient than GridSearchCV for large spaces)
# For a full GridSearchCV, define a smaller, more focused grid after initial exploration.
xgb_param_grid = {
    'n_estimators': [100, 200, 300, 400],
    'learning_rate': [0.01, 0.05, 0.1, 0.2],
    'max_depth': [3, 5, 7, 9],
    'subsample': [0.7, 0.8, 0.9, 1.0],
    'colsample_bytree': [0.7, 0.8, 0.9, 1.0],
    'gamma': [0, 0.1, 0.2, 0.3],
    'lambda': [0.1, 1, 5], # L2 regularization term
    'alpha': [0, 0.1, 0.5] # L1 regularization term
}

# Use RandomizedSearchCV for faster initial exploration
xgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')
xgb_random_search = RandomizedSearchCV(xgb_model, xgb_param_grid, n_iter=30, cv=skf,
                                       scoring='accuracy', n_jobs=-1, verbose=1, random_state=42)
# Using original features for tuning initially. You can also tune on PCA features.
xgb_random_search.fit(X, y)

print(f"Best XGBoost parameters: {xgb_random_search.best_params_}")
print(f"Best XGBoost cross-validation accuracy: {xgb_random_search.best_score_:.4f}")

best_xgb_model = xgb_random_search.best_estimator_

# LightGBM Classifier
print("\n--- Training LightGBM Classifier with Hyperparameter Tuning ---")

lgbm_param_grid = {
    'n_estimators': [100, 200, 300, 400],
    'learning_rate': [0.01, 0.05, 0.1, 0.2],
    'num_leaves': [20, 31, 40, 50],
    'max_depth': [-1, 5, 7, 9], # -1 means no limit
    'min_child_samples': [20, 30, 40],
    'subsample': [0.7, 0.8, 0.9, 1.0],
    'colsample_bytree': [0.7, 0.8, 0.9, 1.0],
    'reg_alpha': [0, 0.1, 0.5], # L1 regularization
    'reg_lambda': [0.1, 1, 5] # L2 regularization
}

lgbm_model = LGBMClassifier(random_state=42)
lgbm_random_search = RandomizedSearchCV(lgbm_model, lgbm_param_grid, n_iter=30, cv=skf,
                                        scoring='accuracy', n_jobs=-1, verbose=1, random_state=42)
# Using original features for tuning
lgbm_random_search.fit(X, y)

print(f"Best LightGBM parameters: {lgbm_random_search.best_params_}")
print(f"Best LightGBM cross-validation accuracy: {lgbm_random_search.best_score_:.4f}")

best_lgbm_model = lgbm_random_search.best_estimator_

# CatBoost Classifier

print("\n--- Training CatBoost Classifier with Hyperparameter Tuning ---")
catboost_params = {
    'iterations': [100, 300, 500],
    'learning_rate': [0.03, 0.1, 0.2],
    'depth': [4, 6, 8, 10],
    'l2_leaf_reg': [1, 3, 5, 7]
}

cat_model = CatBoostClassifier(verbose=0, random_state=42)
cat_search = RandomizedSearchCV(cat_model, catboost_params, n_iter=30, cv=skf, scoring='accuracy', random_state=42, n_jobs=-1, verbose=1)
cat_search.fit(X, y)

print("Best CatBoost parameters:", cat_search.best_params_)
print(f"Best CatBoost CV accuracy: {cat_search.best_score_:.4f}")
best_cat_model = cat_search.best_estimator_

# Random Forest Classifier
print("\n--- Training Random Forest Classifier with Hyperparameter Tuning ---")
rf_param_grid = {
    'n_estimators': [100, 200, 300, 400],
    'max_depth': [None, 5, 10, 15],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'bootstrap': [True, False]
}

rf_model = RandomForestClassifier(random_state=42)
rf_search = RandomizedSearchCV(rf_model, rf_param_grid, n_iter=30, cv=skf, scoring='accuracy', n_jobs=-1, verbose=1, random_state=42)
rf_search.fit(X, y)

print("Best Random Forest parameters:", rf_search.best_params_)
print(f"Best Random Forest CV accuracy: {rf_search.best_score_:.4f}")
best_rf_model = rf_search.best_estimator_

# Cross-validation accuracies
print(f"Best XGBoost cross-validation accuracy: {xgb_random_search.best_score_:.4f}")
print(f"Best LightGBM cross-validation accuracy: {lgbm_random_search.best_score_:.4f}")
print(f"Best CatBoost cross-validation accuracy: {cat_search.best_score_:.4f}")
print(f"Best Random Forest cross-validation accuracy: {rf_search.best_score_:.4f}")

# Model Evaluation

# Evaluate the best XGBoost model
y_pred_xgb = best_xgb_model.predict(X)
print(f"\nXGBoost Training Accuracy: {accuracy_score(y, y_pred_xgb):.4f}")

# Evaluate the best LightGBM model
y_pred_lgbm = best_lgbm_model.predict(X)
print(f"LightGBM Training Accuracy: {accuracy_score(y, y_pred_lgbm):.4f}")

# Evaluate the best CatBoost model
y_pred_cat = best_cat_model.predict(X)
print(f"CatBoost Training Accuracy: {accuracy_score(y, y_pred_cat):.4f}")

# Evaluate the best Random Forest model
y_pred_rf = best_rf_model.predict(X)
print(f"Random Forest Training Accuracy: {accuracy_score(y, y_pred_rf):.4f}")

# Confusion Matrices and Classification Reports
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report
import matplotlib.pyplot as plt

models = {
    "XGBoost": (y_pred_xgb, 'Blues'),
    "LightGBM": (y_pred_lgbm, 'Greens'),
    "CatBoost": (y_pred_cat, 'Reds'),
    "Random Forest": (y_pred_rf, 'cividis')
}

for name, (y_pred, color) in models.items():
    print(f"\n--- {name} Evaluation ---")

    cm = confusion_matrix(y, y_pred)
    print(f"\nConfusion Matrix ({name}):\n{cm}")

    ConfusionMatrixDisplay(cm, display_labels=['Not Transported', 'Transported']).plot(cmap=plt.get_cmap(color))
    plt.title(f"Confusion Matrix - {name}")
    plt.show()

    print(f"\nClassification Report ({name}):")
    print(classification_report(y, y_pred, target_names=['Not Transported', 'Transported']))

# Find the Best Model
model_scores = {
    'XGBoost': xgb_random_search.best_score_,
    'LightGBM': lgbm_random_search.best_score_,
    'CatBoost': cat_search.best_score_,
    'Random Forest': rf_search.best_score_
}


best_model_name = max(model_scores, key=model_scores.get)
print(f"The best model is: {best_model_name} with a cross-validation accuracy of {model_scores[best_model_name]:.4f}")0

# Feature Importance (SHAP values for interpretability)
print("\n--- SHAP Feature Importance (for Best CatBoost Model) ---")
# Using the best CatBoost model for SHAP explanation
explainer = shap.TreeExplainer(best_cat_model)
shap_values = explainer.shap_values(X)

# Summary plot
shap.summary_plot(shap_values, X, plot_type="bar", show=False)
plt.title("SHAP Feature Importance (Mean Absolute SHAP Value)")
plt.tight_layout()
plt.show()

shap.summary_plot(shap_values, X, show=False)
plt.title("SHAP Summary Plot")
plt.tight_layout()
plt.show()

# Predictions for Kaggle Submission

# CatBoost Model is used for the final submission, based on cross-validation accuracy and leaderboard score.
# Here, we'll assume CatBoost was slightly better based on CV accuracy.
final_model = best_cat_model

predictions = final_model.predict(X_test)

# Create submission file
submission_df = pd.DataFrame({
    'PassengerId': test['PassengerId'], # Use original test PassengerId
    'Transported': predictions.astype(bool) # Convert to boolean as per Kaggle's requirement
})

submission_df.to_csv('submission.csv', index=False)
print("\nSubmission file 'submission.csv' created successfully!")
print(submission_df.head())

# Code to download the created CSV file
try:
    from google.colab import files
    files.download('submission.csv')
    print("Your 'submission.csv' file should now be downloading.")
except ImportError:
    print("The 'google.colab.files' module is not available.")
    print("This usually means you are not running in a Google Colab environment.")
    print("If you are in a local Jupyter environment, 'submission.csv' is saved in your current directory.")
    print("You can manually download it from your file explorer.")








